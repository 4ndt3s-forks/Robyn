---
id: demo-R-script
title: Step-by-step Demo
---

import useBaseUrl from '@docusaurus/useBaseUrl';

# Learning with the demo

We recommend to use our [demo.R](https://github.com/facebookexperimental/Robyn/blob/main/demo/demo.R) script in order to
learn and explore what are the steps to build a model using Robyn. This guide is intended to help you walk through the demo, understand how to:
   1. **Load** the data
   2. **Define** model specifications
      1. Specify model **inputs** and parameters
      2. Define **hyperparameter possible values** for adstock and saturation curves
      3. Determine **calibration** inputs
      4. Input a **fix model** setup in one single step
   3. **Build** your initial model
   4. **Select** your preferred initial model **solution**
   5. Calculate **budget allocation** based on the selected model
   6. Execute a **model refresh** to add new recent data
   7. Get **budget allocation** for new model **refresh periods**
   8. Obtain **marginal returns**

---
## Step 1: Load the data
---

Once you have the [demo.R](https://github.com/facebookexperimental/Robyn/blob/main/demo/demo.R) script open, you will have to either, load the simulated dataset, or load your own data. Just change ‘dt_simulated weekly’ name to any name your dataset may have. Please have in mind it should be of the data.frame class.
```
data("dt_simulated_weekly")
head(dt_simulated_weekly)
```

The next step is to load and check the holidays data for Prophet to include them when decomposing seasonality, trend and holiday effects in the data.

Prophet includes data for holidays within 59 countries already.
If your country is not included in the ‘dt_prophet_holidays’ data frame, please manually add it to the dt_prophet_holidays data table.

_Pro Tip:_ _any type of events can be added into this table, not only holidays. E.g. school break, black friday, cyber monday, etc._

```
data("dt_prophet_holidays")
head(dt_prophet_holidays)
```
Finally you should work on defining the robyn object where everything you run will be saved.
The object must be of the extension .Rdata. The object name can be anything different than Robyn too:

```
robyn_object <- "~/Desktop/Robyn.RData"
```

---
## Step 2:  Model specifications

---
### Step 2a-1: Specifying the input data and model parameters
---

The first thing you will have to do is to define **`robyn_inputs()`**, which is the function to input all model parameters and check their correctness for the initial model build.
You will have to define the following input parameters:

- **`dt_input`**
A data.frame. Raw input data which may contain a response variable like revenue, sales or conversions; a set of media variables for channels spend, impressions and/or clicks; and organic, factor or context variables. Load the simulated dataset by running: `data("dt_simulated_weekly")`
- **`dt_holidays`**
A data.frame. Raw input holiday data. Load default Prophet holidays data by running: `data("dt_prophet_holidays")`
- **`date_var`**
A character. This is where you indicate the model what is the name of the date variable. The objective is to tell the model which column to work with for the time series. Daily, weekly and monthly data are supported. Weekly data requires a weekstart of Monday or Sunday. date_var must be of the ''YYYY-MM-DD'' format. E.g. "2020-01-01". Default to automatic date detection.
- **`dep_var`**
A character. This is the name of the dependent variable. It can be sales, conversions or any other numeric or monetary business outcome. Only one dependent variable is allowed.
- **`dep_var_type`**
A character. This is the type of dependent variable, which can be `"revenue"` or `"conversion"`. Revenue indicates a monetary value type (E.g. $), whereas, conversion defines a dependent variable that will be just a numeric value (E.g. total units sold). Only one dependent variable type is allowed and case sensitive.
- **`prophet_vars`**
A character vector. It must Include any of `"trend", "season", "weekday", "holiday"` which are case-sensitive. `"trend", "season", "holiday"` and especially `“weekday”` are highly advised to be included when working with daily data in order to account for weekly seasonality effects. For weekly or monthly data granularity, we recommend to use just `"trend", "season", "holiday"`.
- **`prophet_signs`**
A character vector. Choose any of `c("default", "positive", "negative")`. This input variable controls the signs of coefficients for prophet variables. If the sign is set as “default” it means it will be possible for the model to reflect either a positive or negative effect of the prophet variable `("trend", "season", "weekday", "holiday")` onto the response variable regressed (Conversions, revenue, etc.). The prophet signs vector must have the same length as `prophet_vars`. The sign variables order matters, as it will be mapped literally 1:1 to the `prophet_vars` vector. E.g. If `prophet_vars` is `c("trend", "season", "holiday")` and `prophet_signs` is `c("default", "default", "positive")` then this means trend and season can be either negative or positive, while holiday effects on the dependent variable will be forced to be positive only.
- **`prophet_country`**
A character. Only one country is allowed at a time. This indicates which country to use from the default `“dt_holidays”` Prophet file. Includes national holidays for 59 countries, you may review the list by running: `data("dt_prophet_holidays")`.
- **`context_vars`**
A character vector. These are context variables that can help explain the dependent variable behavior in time and that are not paid media. Most common examples of these are: competitors, price & promotion, temperature, unemployment rate, etc.
- **`context_signs`**
A character vector. Choose any of `c("default", "positive", "negative")`. This input variable controls the signs of coefficients for context_vars. If the sign is set as `“default”` it means it will be possible for the model to reflect either a positive or negative effect of the context variable onto the response variable. Must have the same length as `context_vars`. The sign variables order matters, as it will be mapped literally 1:1 to the `context_vars` vector. E.g. If `context_vars` is `c("promotion", "unemployment")` and `prophet_signs` is `c("default", "negative")` then this means promotion can be either negative or positive, while unemployment effects on the dependent variable will be forced to be negative only.
- **`paid_media_vars`**
A character vector. These are the names of the media variables that will be used in the model. It is recommended to use metrics that better reflect media-exposure such as impressions, clicks or GRPs instead of spend. It is also advised to split media channels into sub-channels (e.g. fb_retargeting, fb_prospecting etc.) to be able to explain more variance. `“paid_media_vars”` only accepts numeric variables.
- **`paid_media_signs`**
A character vector. Choose any of `c("default", "positive", "negative")`. This input variable controls the signs of coefficients for paid_media_vars. If the sign is set as `“default”` it means it will be possible for the model to reflect either a positive or negative effect of the paid media variable onto the response variable. Must have the same length as `paid_media_vars`. The sign variables order matters, as it will be mapped literally 1:1 to the `paid_media_vars` vector. E.g. If `paid_media_vars` is `c("facebook_I", "ooh_S")` and `prophet_signs` is `c("default", "positive")` then this means facebook_I effect can be either negative or positive, while ooh_S effects on the dependent variable will be forced to be positive only.
- **`paid_media_spends`**
A character vector. This input variable indicates the media spends for each of the channels defined on paid_media_vars. We will use spend to link it to exposure level metrics (impressions, clicks, GRPs, etc.) in paid_media_vars, in order to provide ROAS calculation. For spend metrics in `paid_media_vars`, please repeat the same name. `media_spend_vars` must have the same channel to channel matching order and same length as `paid_media_vars`.
- **`organic_vars`**
A character vector. Typically newsletter emails sent, push-notifications, social media posts, etc. Compared to `paid_media_vars`, `organic_vars` are often marketing activities without a clear marketing spend.
- **`organic_signs`**
A character vector. Choose any of `c("default", "positive", "negative")`. This input variable controls the signs of coefficients for `organic_signs`. If the sign is set as `“default”` it means it will be possible for the model to reflect either a positive or negative effect of the organic media variable onto the response variable. Must have the same order and same length as `organic_vars`. The sign variables order matters, as it will be mapped literally 1:1 to the `organic_vars` vector. E.g. If `organic_vars` is `c("newsletter", "push-notifications")` and `prophet_signs` is `c("default", "positive")` then this means newsletter effect can be either negative or positive, while push-notifications effects on the dependent variable will be forced to be positive only.
- **`factor_vars`**
A character vector. Specify which of the provided variables in `organic_vars` or `context_vars` should be used as a factor categorical variable.
- **`adstock`**
A character. Choose any of `c("geometric", "weibull")`. `Weibull` adstock is a two-parametric function and thus more flexible in shape, but it takes longer processing times than the traditional `geometric` one-parametric function. Time estimation: with geometric adstock, 2000 iterations * 5 trials on 8 cores, it should take less than 30 minutes. Whereas weibull takes at least twice as much time.
- **`hyperparameters`**
List containing the hyperparameter lower and upper ranges. The names of the elements in the list must be identical to the output of `hyper_names()`
- **`window_start`**
A character. Set the start date of the modelling period. The window start will determine the start date of the data period within your dataset you will be using to specifically regress the effects of media, organic and context variables on your dependent variable. We recommend using a full `“dt_input”` dataset with a minimum of 1 year of history, as it will be used in full for the model calculation of trend, seasonality and holidays effects. Whereas the window period will determine how much of the full data set will be used for media, organic and context variables. E.g. Uploading and using 2 years of data in `“dt_input”` but determining `window_start` and `window_end` as the last 6 months which reflect better the current business and/or marketing investment reality for budget decision making.
- **`window_end`**
A character. Set end date of modelling period. Recommended to have ratio of independent variable data points of 1:10.
The window end will determine the end date of the data period within your dataset you will be using to specifically regress the effects of media, organic and context variables on your dependent variable. We recommend using a full `“dt_input”` dataset with a minimum of 1 year of history, as it will be used in full for the model calculation of trend, seasonality and holidays effects. Whereas the window period will determine how much of the full data set will be used for media, organic and context variables. E.g. Uploading and using 2 years of data in `“dt_input”` but determining `window_start` and `window_end` as the last 6 months which reflect better the current business and/or marketing investment reality for budget decision making.
- **`cores`**
An integer. Default to `parallel::detectCores()`
- **`iterations`**
An integer. Recommended 2000 for `defaultnevergrad_algo = "TwoPointsDE"`
- **`trials`**
An integer. Recommended 5 for `default nevergrad_algo = "TwoPointsDE"`
- **`nevergrad_algo`**
A character. Default to `"TwoPointsDE"`. Options arec("DE","TwoPointsDE", "OnePlusOne", "DoubleFastGADiscreteOnePlusOne", "DiscreteOnePlusOne", "PortfolioDiscreteOnePlusOne", "NaiveTBPSA", "cGA", "RandomSearch")
- **`calibration_input`**
A data.table. It is optional to provide experimental results. We strongly recommend using experimental and causal results that are considered ground truth to calibrate MMM. Usual experiment types are people-based (e.g. Facebook conversion lift) and geo-based (e.g. Facebook GeoLift). Currently, Robyn only accepts point-estimates as calibration input. E.g. with a 50/50 split between control and test groups if you identify $70k in sales on holdout vs. $110k on test. Then you may input $110k-$70k = $40k as the incremental point-estimate for calibration.
- **`InputCollect`**
Default to NULL. `robyn_inputs`'s output when hyperparameters are not yet set.
---


### Step 2a-2: Defining hyperparameters

All variables in `paid_media_vars` or `organic_vars` require hyperparameters and will be transformed by adstock and saturation curves. The difference between `paid_media_vars` and `organic_vars` is that `paid_media_vars` require spend to be specified in the `paid_media_spends` vector.

#### How to setup the hyperparameters

1. Ensure you have the correct **hyperparameter names**:
    - Run **`hyper_names()`** to get the correct hyperparameter names. All the names in hyperparameters object must be equal to the names from **`hyper_names()`**, case sensitive.
2. Follow the guidelines for defining **hyperparameter ranges**:
    - Please note that for geometric adstock, it is required to use theta, alpha and gamma. Whereas for weibull adstock, it is mandatory to use shape, scale, alpha and gamma.
        1. **Theta**: In geometric adstock, theta is the decay rate. For example, if the time unit for the model is weekly, it will represent the percentage of effect each week that is carried over to the following week. The guideline for most common media is: TV c(0.3, 0.8), OOH/Print/Radio c(0.1, 0.4), digital c(0, 0.3).
        2. **Shape**: In weibull adstock, shape controls the decay shape. Recommended ranges are c(0.0001, 2). The larger, the more S-shape. The smaller, the more L-shape.
        3. **Scale**: In weibull adstock, scale controls the decay inflection point. A very conservative recommended range is c(0, 0.1), because scale can increase adstocking half-life greatly.
        4. **Alpha**: In s-curve transformation with hill function (Diminishing returns), alpha is the parameter that controls the shape between exponential and s-shape. The larger the alpha, the more S-shape. The smaller, the more C-shape.
        5. **Gamma**: In s-curve transformation with hill function (Diminishing returns), gamma controls the inflection point. Recommended range is c(0.3, 1). The larger the gamma, the later the inflection point in the response curve.
3. Set each **hyperparameter range**.
    - They either contain two values e.g. c(0, 0.5), or only one value. Defining a single value fixes the parameter and prevents the model from exploring solutions within a certain range.

---
#### Helper plots
There are a couple of helper plots that can be useful to understand better how **adstock** and **saturation** curves change when altering their hyperparameters.
#### plot_adstock
Set to **`plot_adstock(TRUE)`** and run the command. This will plot the adstock transformation examples, helping to understand **geometric theta** and **weibull shape/scale** transformation.

<img alt="adstockintro chart" src={useBaseUrl('/img/adstock-qs.png')} />

Set to **`plot_saturation(TRUE)`** and run the command. This will plot the saturation curve transformation example, helping to understand hill, **alpha** and **gamma** transformation.

<img alt="saturation chart" src={useBaseUrl('/img/saturation-qs.png')} />

---
#### Examples for hypermarameter definitions
##### Defining hyper_names for geometric adstock

```
hyper_names(adstock = "geometric", all_media = InputCollect$all_media)
hyperparameters <- list(
  facebook_I_alphas = c(0.5, 3), # example bounds for alpha
  facebook_I_gammas = c(0.3, 1), # example bounds for gamma
  facebook_I_thetas = c(0, 0.3), # example bounds for theta
  tv_S_alphas = c(0.5, 3),
  tv_S_gammas = c(0.3, 1),
  tv_S_thetas = c(0.3, 0.8),
  newsletter_alphas = c(0.5, 3),
  newsletter_gammas = c(0.3, 1),
  newsletter_thetas = c(0.1, 0.4)
)
```
##### Defining hyper_names for weibull adstock

```
hyper_names(adstock = "weibull", all_media = InputCollect$all_media)

hyperparameters <- list(
  facebook_I_alphas = c(0.5, 3), # example bounds for alpha
  facebook_I_gammas = c(0.3, 1) # example bounds for gamma
  facebook_I_shapes = c(0.0001, 2), # example bounds for shape
  facebook_I_scales = c(0, 0.1), # example bounds for scale
  tv_S_alphas = c(0.5, 3),
  tv_S_gammas = c(0.3, 1),
  tv_S_shapes = c(0.0001, 2),
  tv_S_scales = c(0, 0.1),
  newsletter_alphas = c(0.5, 3),
  newsletter_gammas = c(0.3, 1),
  newsletter_shapes = c(0.0001, 2),
  newsletter_scales = c(0, 0.1)
)
```
---
### Step 2a-3: Add hyperparameters into `robyn_inputs()`
```
InputCollect <-
  robyn_inputs(InputCollect = InputCollect, hyperparameters = hyperparameters)
```

---
### Step 2a-4: Model calibration (Optional)

#### How to input details from experiments

1. We strongly recommend using experimental and causal results that are considered ground truth to calibrate MMM. Usual experiment types are people-based (e.g. Facebook conversion lift) and geo-based (e.g. Facebook GeoLift).
2. Robyn only accepts point-estimates as a calibration input. For example, if 10k$ spend is tested against a holdout for channel A, then input the incremental absolute return as a point-estimate for the test period just like the example below.
3. The point-estimate must match the regular spend for the channel measured. For example, if channel A usually has $100k weekly spend and the experimental holdout is 70%, input the point-estimate for the incremental sales resulting from the proportional $30k spent in test, without the $70k from the audience held outside of the study.

```
 dt_calibration <- data.frame(
   # channel name must be in paid_media_vars
     channel = c("facebook_I",  "tv_S", "facebook_I")

   # liftStartDate must be within input data range
   , liftStartDate = as.Date(c("2018-05-01", "2017-11-27", "2018-07-01"))

   # liftEndDate must be within input data range
   , liftEndDate = as.Date(c("2018-06-10", "2017-12-03", "2018-07-20"))

   # The provided value must be tested on the same
   # campaign level than the model and same metric as dep_var_type
   , liftAbs = c(400000, 300000, 200000)
 )

 InputCollect <- robyn_inputs(InputCollect = InputCollect
                              , calibration_input = dt_calibration)
```

---
### Step 2b: For known model specification, how to set it up in one single step


You may specify hyperparameters as in 2a-2 and optionally calibration as in 2a-4 and provide them directly in robyn_inputs() function:
```
 InputCollect <- robyn_inputs(
   dt_input = dt_simulated_weekly
...
...
...
   ,hyperparameters = hyperparameters # as in 2a-2 above
   ,calibration_input = dt_calibration # as in 2a-4 above
 )
```

---
## Step 3: Build the initial model
---

Please run first **`?robyn_run`** to check the model's parameters definition:

The `robyn_run()` function consumes the output from `robyn_input()`, runs the `robyn_mmm()` functions and plots and collects the results into a defined folder.

```
OutputCollect <- robyn_run(
  InputCollect = InputCollect # feed in all model specification
  , plot_folder = robyn_object # plots will be saved in the same folder as robyn_object
  , pareto_fronts = 3
  , plot_pareto = TRUE
  )
```
Besides the [one-pager plots](/img/ModelResults1.png): there are **4 .csv outputs** that are saved in the folder for further usage:
- ***pareto_hyperparameters.csv***: hyperparameters per pareto output model
- ***pareto_aggregated.csv***: aggregated decomposition per independent variable of all pareto outputs
- ***pareto_media_transform_matrix.csv***: all media transformation vectors
- ***pareto_alldecomp_matrix.csv***: all decomposition vectors of independent variables

---
#### **`robyn_run()` arguments**
---

**`InputCollect`**
A list. Contains all input parameters for the model. Required when `robyn_object` is not provided.

**`plot_folder`**
A character. Path for saving plots. Default to `robyn_object` and saves plot in the same directory as `robyn_object`.

**`pareto_fronts`**
An integer. Number of Pareto fronts for the output. `pareto_fronts = 1` returns the best models trading off `NRMSE & DECOMP.RSSD`. Increase `pareto_fronts` to get more model choices.

**`plot_pareto`**
A boolean. Set to FALSE to deactivate plotting and saving model one-pagers. Used when testing models.

**`refresh`**
A boolean. Set to `TRUE` when used in `robyn_refresh()`

**`dt_hyper_fixed`**
A data.frame. Only provide when loading old model results. It consumes hyperparameters from saved csv `pareto_hyperparameters.csv`.

**`ui`**
A boolean. Save additional outputs for UI usage. List outcome.

---

### Pareto model solutions plot
After running the model, a Pareto-front chart for the initial model build will be displayed.
This chart shows the performance of the multi-objective optimization from the evolutionary algorithm
platform Nevergrad over 10k iterations in total.

<img alt="pareto chart 2" src={useBaseUrl('/img/pareto2.png')} />

The two axes (NRMSE on x and DECOMP.RSSD on y) are the two objective functions to be minimized.
As the iteration increases, a trend down the lower left corner of the coordinate can be clearly observed.
This is a proof of Nevergrad's ability to drive the model result towards an optimal direction.
The red lines are Pareto-fronts 1-3 and contains the best possible model results from all iterations.

---
## Step 4: Select and save your preferred initial model

Please compare all model [one-pager plots](/img/ModelResults1.png) in the plot folder and select the one that better represents your business reality:

```
OutputCollect$allSolutions # get all model IDs in result
select_model <- "5_126_5" # select one from above
robyn_save(robyn_object = robyn_object # model object location and name
           , select_model = select_model # selected model ID
           , InputCollect = InputCollect # all model input
           , OutputCollect = OutputCollect # all model output
)
```
---
## Step 5: Calculate budget allocation based on the selected model above

The budget allocator result requires further validation. Please use these results with caution. Avoid using or interpreting budget allocation results if the selected results do not meet your business expectations.

```
# Check media summary for selected model
OutputCollect$xDecompAgg[solID == select_model & !is.na(mean_spend)
                         , .(rn, coef,mean_spend, mean_response, roi_mean
                             , total_spend, total_response=xDecompAgg, roi_total, solID)]
```

Run **`?robyn_allocator`** to check if parameter definitions are correct.

Run the `"max_historical_response"` scenario which answers the question:
  _"How can I improve my overall media investment efficiency, assuming the same historical spend level. What is the optimal spend mix to maximize the response (E.g. sales)?"_

```
AllocatorCollect <- robyn_allocator(
  InputCollect = InputCollect
  , OutputCollect = OutputCollect
  , select_model = select_model
  , scenario = "max_historical_response"
  , channel_constr_low = c(0.7, 0.7, 0.7, 0.7, 0.7)
  , channel_constr_up = c(1.2, 1.5, 1.5, 1.5, 1.5)
)
```

Observe the allocator results. Last column **"optmResponseUnitTotalLift"** is the total response lift.

```
AllocatorCollect$dt_optimOut
```

Run the `"max_response_expected_spend"` scenario which answers:
  _"What is the maximum response I can obtain for a given total spend, assuming same historical saturation curves. What is the spend mix?"_

```
AllocatorCollect <- robyn_allocator(
  InputCollect = InputCollect
  , OutputCollect = OutputCollect
  , select_model = select_model
  , scenario = "max_response_expected_spend"
  , channel_constr_low = c(0.7, 0.7, 0.7, 0.7, 0.7)
  , channel_constr_up = c(1.2, 1.5, 1.5, 1.5, 1.5)
  , expected_spend = 1000000 # Total spend to be simulated
  , expected_spend_days = 7 # Duration of expected_spend in days
)
```

Observe the allocator results. The column **"optmResponseUnitTotal"** is the maximum unit (weekly with simulated dataset) response. **"optmSpendShareUnit"** is the optimum spend share.

```
AllocatorCollect$dt_optimOut
```

---

### Budget allocator example plots

Below there is an example of a budger allocator result plot which is typically saved within the plot folder with all model results plots where your Robyn.RData object resides.
You will find it with the name: _[select_model_SolID]_reallocated.png_

<img alt="pareto chart 2" src={useBaseUrl('/img/budgerAllocator1.png')} />

---
#### `robyn_allocator()` description
---

The `robyn_allocator()` function returns a new split of media variable spends that maximizes the total media response.

---
#### `robyn_allocator()` Usage
---

```
robyn_allocator(
  robyn_object = NULL,
  select_build = NULL,
  InputCollect = NULL,
  OutputCollect = NULL,
  select_model = NULL,
  optim_algo = "SLSQP_AUGLAG",
  scenario = "max_historical_response",
  expected_spend = NULL,
  expected_spend_days = NULL,
  channel_constr_low = 0.5,
  channel_constr_up = 2,
  maxeval = 1e+05,
  constr_mode = "eq"
)
```
---
#### `robyn_allocator()` Arguments
---

- **`robyn_object`**
A character. This is the path of the `Robyn.RData` object that contains all previous modeling information.
- **`select_build`**
An integer. Default to the latest model build. `select_build = 0` selects the initial model. `select_build = 1` selects the first refresh model.
- **`InputCollect`**
A list. Contains all input parameters for the model. Required when `robyn_object` is not provided.
- **`OutputCollect`**
A list. Containing all model results. Required when `robyn_object` is not provided.
- **`select_model`**
A character. A model `SolID`. When `robyn_object` is provided, `select_model` defaults to the already selected `SolID`. When `robyn_object` is not provided, `select_model` must be provided with `InputCollect` and `OutputCollect`, and must be one of the solutions in `OutputCollect$allSolutions`.
- **`optim_algo`**
A character. Default is "SLSQP_AUGLAG", short for "Sequential Least-Squares Quadratic Programming" and "Augmented Lagrangian". Alternatively, ""MMA_AUGLAG", short for "Method of Moving Asymptotes". More details see the documentation of NLopt [here](https://nlopt.readthedocs.io/en/latest/NLopt_Algorithms/).
- **`scenario`**
A character. Accepted options are: `"max_historical_response"` or `"max_response_expected_spend"`.
`"max_historical_response"` simulates the scenario "what's the optimal media spend allocation given the same average spend level in history?", while `"max_response_expected_spend"` simulates the scenario "what's the optimal media spend allocation of a given future spend level for a given period?"
- **`expected_spend`**
Numeric. The expected future spend volume. Only applicable when `scenario = "max_response_expected_spend"`.
- **`expected_spend_days`**
An integer. The duration of the future spend volume in `expected_spend`. Only applies when `scenario = "max_response_expected_spend"`.
- **`channel_constr_low, channel_constr_up`**
Numeric vector. The lower and upper bounds for each paid media variable when maximizing total media response. `channel_constr_low = 0.7` means the minimum spend of the channel solution can be as low as 70% of the historical average. Whereas `channel_constr_up = 1.5` means that the maximum spend of the variable can be up to 150% the historical average. The upper bound must be >= than the lower bound. Both must have the same length and order as `paid_media_vars`.
- **`maxeval`**
An integer. The maximum iteration of the global optimization algorithm. Defaults to 100000.
- **`constr_mode`**
A character. Options are "eq" or "ineq", indicating constraints with equality or inequality.

---

## Step 6: Model refresh based on selected model and saved Robyn.RData object

NOTE: must run robyn_save to select and save an initial model first, before refreshing below
The robyn_refresh() function is suitable for updating within "reasonable periods"
Two situations are considered better to rebuild model:
1. When most **data is new**. If initial model has 100 weeks and 80 weeks new data is added in refresh, it might be better to rebuild the model
2. When **new variables** are added

---
Please run **`?robyn_refresh`** to check parameter definition

```
Robyn <- robyn_refresh(
  robyn_object = robyn_object
  , dt_input = dt_simulated_weekly
  , dt_holidays = dt_prophet_holidays
  , refresh_steps = 13
  , refresh_mode = "auto"
  , refresh_iters = 1000 # Iteration for refresh. 600 is rough estimation. We'll still
  # figuring out what's the ideal number.
  , refresh_trials = 3
)
```

Besides the plots, there are **4 .csv outputs** saved in the folder for further usage:
- ***report_hyperparameters.csv***: hyperparameters of all selected model for reporting
- ***report_aggregated.csv***: aggregated decomposition per independent variable
- ***report_media_transform_matrix.csv***: all media transformation vectors
- ***report_alldecomp_matrix.csv***: all decomposition vectors of independent variables

---

### Robyn refresh models example plots
Below there is an example of the model refresh plot results and how they are fit in time.
As well as, their corresponding plots which reflect the decomposition of each variable effect and ROAS.

#### Reporting model refresh time-series fit
You may observe in the plot below that all initial and refresh builds are included sequentially.
For the refresh builds, only the new periods added will be appended.
The assembled R-squared is adjusted and describes the fit of the assembled actual & fitted lines below.
Refresh builds can have different window lengths (parameter refresh_step in the robyn_refresh() function).

<img alt="pareto chart 2" src={useBaseUrl('/img/refresh-window.png')} />

#### Reporting model refresh decomposition & ROAS
The chart below shows the decomposition of all predictors per each model build.
The baseline variable is the sum of all prophet variables (trend, season, weekday, holiday) and the intercept.
Please have in mind that the below data is simulated and for illustration purposes only.

<img alt="pareto chart 2" src={useBaseUrl('/img/refresh-reporting.png')} />


---
#### `robyn_refresh()` description
The `robyn_refresh()` function builds updated models based on the previously built models saved in the Robyn.RData object specified in robyn_object.
For example, when updating the initial build with 4 weeks of new data, `robyn_refresh()` consumes the selected model of the initial build.

What Robyn does, is to set lower and upper bounds of hyperparameters for the new build around the selected hyperparameters of the previous build,
stabilizes the effect of baseline variables across old and new builds and regulates the new effect share of media variables towards the latest spend level.
It returns aggregated results with all previous builds for reporting purposes and produces reporting plots.

---
#### `robyn_refresh()` usage
```
robyn_refresh(
  robyn_object,
  dt_input = dt_input,
  dt_holidays = dt_holidays,
  refresh_steps = 4,
  refresh_mode = "manual",
  refresh_iters = 1000,
  refresh_trials = 3,
  plot_pareto = TRUE
)
```
---
#### `robyn_refresh()` arguments

- **`robyn_object`**
A character. Path of the `Robyn.RData` object that contains all previous modeling information.
- **`dt_input`**
A data.frame. It should include all previous data and newly added data for the refresh.
- **`dt_holidays`**
A data.frame. Raw input holiday data. Load standard Prophet holidays using `data("dt_prophet_holidays")`.
- **`refresh_steps`**
An integer. It controls how many time units the refresh model build will move forward. For example, `refresh_steps = 4` on weekly data means the `InputCollect$window_start` & `InputCollect$window_end` will move forward 4 weeks.
- **`refresh_mode`**
A character. Options are "auto" and "manual". In auto mode, the `robyn_refresh()` function builds refresh models following given `refresh_steps` repeatedly until there is no more data available. In manual mode, the `robyn_refresh()` moves forward the `refresh_steps` only once.
- **`refresh_iters`**
An integer. The number of iterations per refresh. The rule of thumb is, the more new data added, the more iterations needed.
- **`refresh_trials`**
An integer. The number of trials per refresh. Defaults to 5 trials.
- **`plot_pareto`**
A logical value. Set it to FALSE to deactivate plotting and saving model onepagers, commonly used when testing models.

---
## Step 7: Get budget allocation recommendation based on selected refresh runs

Please run **`?robyn_allocator`** to check if parameter definitions are correct.

```
AllocatorCollect <- robyn_allocator(
  robyn_object = robyn_object
  , select_build = 3 # Use third refresh model
  , scenario = "max_response_expected_spend"
  , channel_constr_low = c(0.7, 0.7, 0.7, 0.7, 0.7)
  , channel_constr_up = c(1.2, 1.5, 1.5, 1.5, 1.5)
  , expected_spend = 2000000 # Total spend to be simulated
  , expected_spend_days = 14 # Duration of expected_spend in days
)

AllocatorCollect$dt_optimOut
```
---
#### `robyn_allocator()` description
The `robyn_allocator()` function returns a new split of media variable spends that maximizes the total media response.

---
#### `robyn_allocator()` Usage

```
robyn_allocator(
  robyn_object = NULL,
  select_build = NULL,
  InputCollect = NULL,
  OutputCollect = NULL,
  select_model = NULL,
  optim_algo = "SLSQP_AUGLAG",
  scenario = "max_historical_response",
  expected_spend = NULL,
  expected_spend_days = NULL,
  channel_constr_low = 0.5,
  channel_constr_up = 2,
  maxeval = 1e+05,
  constr_mode = "eq"
)
```
---
#### `robyn_allocator()` Arguments

- **`robyn_object`**
A character. This is the path of the `Robyn.RData` object that contains all previous modeling information.
- **`select_build`**
An integer. Default to the latest model build. `select_build = 0` selects the initial model. `select_build = 1` selects the first refresh model.
- **`InputCollect`**
A list. Contains all input parameters for the model. Required when `robyn_object` is not provided.
- **`OutputCollect`**
A list. Containing all model results. Required when `robyn_object` is not provided.
- **`select_model`**
A character. A model `SolID`. When `robyn_object` is provided, `select_model` defaults to the already selected `SolID`. When `robyn_object` is not provided, `select_model` must be provided with `InputCollect` and `OutputCollect`, and must be one of the solutions in `OutputCollect$allSolutions`.
- **`optim_algo`**
A character. Default is "SLSQP_AUGLAG", short for "Sequential Least-Squares Quadratic Programming" and "Augmented Lagrangian". Alternatively, ""MMA_AUGLAG", short for "Method of Moving Asymptotes". More details see the documentation of NLopt [here](https://nlopt.readthedocs.io/en/latest/NLopt_Algorithms/).
- **`scenario`**
A character. Accepted options are: `"max_historical_response"` or `"max_response_expected_spend"`.
"max_historical_response" simulates the scenario "what's the optimal media spend allocation given the same average spend level in history?", while "max_response_expected_spend" simulates the scenario "what's the optimal media spend allocation of a given future spend level for a given period?"
- **`expected_spend`**
Numeric. The expected future spend volume. Only applicable when `scenario = "max_response_expected_spend"`.
- **`expected_spend_days`**
An integer. The duration of the future spend volume in `expected_spend`. Only applies when `scenario = "max_response_expected_spend"`.
- **`channel_constr_low, channel_constr_up`**
Numeric vector. The lower and upper bounds for each paid media variable when maximizing total media response. `channel_constr_low = 0.7` means the minimum spend of the channel solution can be as low as 70% of the historical average. Whereas `channel_constr_up = 1.5` means that the maximum spend of the variable can be up to 150% the historical average. The upper bound must be >= than the lower bound. Both must have the same length and order as `paid_media_vars`.
- **`maxeval`**
An integer. The maximum iteration of the global optimization algorithm. Defaults to 100000.
- **`constr_mode`**
A character. Options are "eq" or "ineq", indicating constraints with equality or inequality.

---
## Step 8: Obtain marginal returns

The **`robyn_response()`** function returns the response for a given spend level of a given `paid_media_vars` from a selected model result of a selected model build (initial model, refresh model etc.).

---
#### `robyn_response()` Usage

```
robyn_response(
  robyn_object = NULL,
  select_build = NULL,
  paid_media_var = NULL,
  select_model = NULL,
  spend = NULL,
  dt_hyppar = NULL,
  dt_coef = NULL,
  InputCollect = NULL
)
```
---
#### `robyn_response()` Arguments

- **`robyn_object`**
A character. Path of the `Robyn.RData` object that contains all previous modeling information.
- **`select_build`**
An integer. Its default is the latest model build. `select_build = 0` selects the initial model. `select_build = 1` selects the first refresh model.
- **`paid_media_var`**
A character. The selected paid media variable for the response. Must be one of the paid media variables within `InputCollect$paid_media_vars`
- **`select_model`**
A character. A model `SolID`. When `robyn_object` is provided, `select_model` defaults to the already selected `SolID`. When `robyn_object` is not provided, `select_model` must be provided with `InputCollect` and `OutputCollect`, and must be one of the solutions in `OutputCollect$allSolutions`.
- **`spend`**
Numeric. The desired spend level to return a response for.
- **`dt_hyppar`**
A data.table. When `robyn_object` is not provided, use `dt_hyppar = OutputCollect$resultHypParam`. It must be provided along with `select_model`, `dt_coef` and `InputCollect`.
- **`dt_coef`**
A data.table. When `robyn_object` is not provided, use `dt_coef = OutputCollect$xDecompAgg`. It must be provided along with `select_model`, `dt_hyppar` and `InputCollect`.
- **`InputCollect`**
A list. Contains all input parameters for the model. Required when robyn_object is not provided.
---

Below, there is an example of how to get marginal ROI of next 1000$ from an initial $80k spend level for the search channel:

First run **`?robyn_response`** to check the parameter definition

```
# Get response for 80k
Spend1 <- 80000
Response1 <- robyn_response(
  robyn_object = robyn_object
  #, select_build = 1 # 2 means the second refresh model. 0 means the initial model
  , paid_media_var = "search_clicks_P"
  , spend = Spend1)
Response1/Spend1 # ROI for search 80k

# Get response for 81k
Spend2 <- Spend1+1000
Response2 <- robyn_response(
  robyn_object = robyn_object
  #, select_build = 1
  , paid_media_var = "search_clicks_P"
  , spend = Spend2)
Response2/Spend2 # ROI for search 81k

# Marginal ROI of next 1000$ from 80k spend level for search
(Response2-Response1)/(Spend2-Spend1)

```
---
### Optional: get old model results
---

#### Get old hyperparameters and select model

```
dt_hyper_fixed <- fread("~/Desktop/2021-07-29 00.56 init/pareto_hyperparameters.csv")
select_model <- "1_24_5"
dt_hyper_fixed <- dt_hyper_fixed[solID == select_model]

OutputCollectFixed <- robyn_run(
  # InputCollect must be provided by robyn_inputs with same dataset and parameters as before
  InputCollect = InputCollect
  , plot_folder = robyn_object
  , dt_hyper_fixed = dt_hyper_fixed)
```

#### Save Robyn object for further refresh
```
robyn_save(robyn_object = robyn_object
           , select_model = select_model
           , InputCollect = InputCollect
           , OutputCollect = OutputCollectFixed)
```
---
